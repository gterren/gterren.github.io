@article{MAMMOLI2019254,
title = {An experimental method to merge far-field images from multiple longwave infrared sensors for short-term solar forecasting},
journal = {Solar Energy},
volume = {187},
pages = {254-260},
year = {2019},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2019.05.052},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X19305158},
author = {Andrea Mammoli and Guillermo Terren-Serrano and Anthony Menicucci and Thomas P. Caudell and Manel Martínez-Ramón},
keywords = {Solar forecasting, Sky imaging, Longwave infrared, Image stitching},
abstract = {In a system used for short-term forecasting of solar irradiance, multiple longwave infrared sensors are used to acquire an image of a large, continuous section of the sky dome. The field of view of each sensor is directed at a particular, fixed portion of the sky dome, with some overlap between adjacent edges of each field of view to ensure that a continuous image can be acquired. Because of unavoidable imperfections in the optical components and in the alignment of the sensors, and because of the complex optics, it is difficult to pre-determine adjustable parameters in the geometric transformations required to merge the multiple images into a single one. Instead, it is possible to do this experimentally, by rotating the imaging sensor array via a two-axis rotating platform, using the sun itself as a convenient far-field reference object, and using the images collected to generate relations that map each sensor pixel into an altitude-azimuth direction, α and ϕ respectively. The experimental proof of concept of this method is described here.}
}