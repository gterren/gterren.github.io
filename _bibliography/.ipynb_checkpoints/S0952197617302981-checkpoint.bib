@article{GARCIAHINDE2018157,
title = {Evaluation of dimensionality reduction methods applied to numerical weather models for solar radiation forecasting},
journal = {Engineering Applications of Artificial Intelligence},
volume = {69},
pages = {157-167},
year = {2018},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2017.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0952197617302981},
author = {O. García-Hinde and G. Terrén-Serrano and M.Á. Hombrados-Herrera and V. Gómez-Verdejo and S. Jiménez-Fernández and C. Casanova-Mateo and J. Sanz-Justo and M. Martínez-Ramón and S. Salcedo-Sanz},
keywords = {Dimensionality reduction, Interpretability, Solar radiation forecast, Weather research and forecasting model, Support vector regression, Restricted Boltzmann machine},
abstract = {The interest in solar radiation prediction has increased greatly in recent times among the scientific community. In this context, Machine Learning techniques have shown their ability to learn accurate prediction models. The aim of this paper is to go one step further and automatically achieve interpretability during the learning process by performing dimensionality reduction on the input variables. To this end, three non standard multivariate feature selection approaches are applied, based on the adaptation of strong learning algorithms to the feature selection task, as well as a battery of classic dimensionality reduction models. The goal is to obtain robust sets of features that not only improve prediction accuracy but also provide more interpretable and consistent results. Real data from the Weather Research and Forecasting model, which produces a very large number of variables, is used as the input. As is to be expected, the results prove that dimensionality reduction in general is a useful tool for improving performance, as well as easing the interpretability of the results. In fact, the proposed non standard methods offer important accuracy improvements and one of them provides with an intuitive and reduced selection of features and mesoscale nodes (around 10% of the initial variables centered on three specific nodes).}
}